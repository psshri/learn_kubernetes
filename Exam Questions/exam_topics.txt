Pods and labels
Deployments
Services
PV and PVCs
RBAC
Cluster Upgrade
ETCD Backup and Restore
Manual Scheduling
Metrics
Network Policies
Volumes
Debugging
Ingress
Namespaces
Daemonsets
Configmaps
Secrets
JSONPath

Common Questions
-------------------
-ETCD backup and restore
-Upgrade cluster to v1.2x.x
-RBAC: ClusterRole, ClusterRoleBinding, Role, RoleBinding, Service Accounts
-Find nodes that are ready and taints not set as NoSchedule
-Find pod that is consuming maximum CPU from all the pods in a given namespace
-Add a sidecar container that prints the logs of main container. You need to 
create emptyDir and mount to both the containers. Command to print logs will be
given
-Create a PVC of 10Mi and mount it to a container. Later patch PVC to 70Mi.
-Create a pod with 2 containers. Image names and other info will be provided
-Scale a deployment to 3 replicas
-Create a deployment with X image and Y tag. Change the Y tag to Z and record
the changes
-Create a pod and manually schedule it with NodeSelector(disk:ssd)
-Schedule a pod on master node without modifying labels on the node
-Drain all workloads from a node
-Create a network policy that allows all pods in Y namespace to talk to all 
pods in X namespace on port 5432
-A kubernetes worker node is in state NotReady. Investigate why this is the case,
and perform any appropriate steps to bring the node to a ready state
-Setting CPU and memory limits to containers of a pod
-Security contexts to add user id and group id to pod, add additional capabilities
like SYS_TIME and NET_ADMIN
-Sort all pods by their order of creation
-Write all namespaced resources to a file
-Filter pods by certain labels and write the results to a file
-Delete kube-proxy container from Y node. Use crictl ps and crictl rm 
-Create a pod with given labels
-Add a secondary container that runs certain commands like sleep 2000
-Write a command to list all clusters from kubeconfig file into file
-Create a pod with some environment variables
-Mount an existing secret as a volume

-----------------------------------------------------------------

ETCD DATABASE BACKUP AND RESTORE

types of questions
1) backup 
2) restore

etcd starts a service that listens on port 2379 by default

if you install k8s using kubeadm, then etcd is provisioned as a static pod 
inside kube-system namespace 

kubectl describe pods etcd-controlplane -n kube-system

backing up an etcd cluster can be accomplished in two ways: etcd built-in 
snapshot or volume snapshot 

go to 'operating etcd clusters for kubernetes' and go to 
backing up an etcd cluster->volume snapshot->snapshot using etcdctl options

ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=<trusted-ca-file> --cert=<cert-file> --key=<key-file> \
  snapshot save <backup-file-location>

fill in values from describe command and in backupfilelocation fill
/opt/snapshot-pre-boot.db

follow the below steps to restore the database

ETCDCTL_API=3 etcdctl snapshot restore --data-dir <data-dir-location> snapshotdb

ETCDCTL_API=3 etcdctl snapshot restore --data-dir=/var/lib/etcd-backup /opt/snapshot-pre-boot.db

now direct the manifest file of etcd to use this backup

go to /etc/kubernetes/manifests

vim etcd.yaml

update the path under hostPath 


if certificate file location is given in question then use it otherwise use
the one mentioned in describe command

==============================================================================

PERSISTENT VOLUME AND PERSISTENT VOLUME CLAIM

the pvc and the pod that uses that pvc has to be in the same namespace. pv will
always be a part of the default namespace

pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypvlog
spec:
  capacity:
    storage: 100Mi
  accessModes: 
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  hostPath: 
    path: /pv/log

pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pv-claim-log
spec:
  accessModes:
    - ReadWriteMany
  resources: 
    requests:
      storage: 50Mi

pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-nginx-pod
spec: 
  containers:
  - name: mypod
    image: nginx
    volumeMounts: 
    - mountPath: /log
      name: mypd
  volumes:
  - name: mypd
    persistentVolumeClaim: 
      claimName: pv-claim-log

pv-pvc is 1-1 mapping only

pv is not namespaced
pvc is namespaced
pods are namespaced